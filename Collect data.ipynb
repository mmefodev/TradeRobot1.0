{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File collects data for a machine(deep) learning model to make prediction of next price movement\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import time\n",
    "import tinvest as ti\n",
    "import pandas as pd\n",
    "# Tinkoff info and initial parameters\n",
    "TOKEN_SANDBOX =  # Your sandbox token\n",
    "client = ti.SyncClient(TOKEN_SANDBOX, use_sandbox=True)\n",
    "FIGI = client.get_market_search_by_ticker('MRNA').payload.instruments[0].figi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample #0 added\n",
      "Sample #1 added\n",
      "Sample #2 added\n",
      "Sample #3 added\n",
      "Sample #4 added\n",
      "Sample #5 added\n",
      "Sample #6 added\n",
      "Collection complete!\n"
     ]
    }
   ],
   "source": [
    "candle_resolution = ti.CandleResolution.min1\n",
    "duration = 3600*10\n",
    "sample_time = 60\n",
    "period = 3\n",
    "depth = 20\n",
    "\n",
    "# Streaming coroutine. Makes live changing pool of the last values of candles and orderbooks\n",
    "async def stream(token,figi,collect_duration,candle_resolution,depth,countdown=60-time.gmtime().tm_sec-time.time()%1):\n",
    "    global cur_events\n",
    "    cur_events = np.zeros((3),dtype=object)\n",
    "    start_time = time.time()\n",
    "    async with ti.Streaming(token) as streaming:\n",
    "        try:\n",
    "            await streaming.candle.subscribe(figi, candle_resolution)\n",
    "            await streaming.orderbook.subscribe(figi, depth)\n",
    "            await streaming.instrument_info.subscribe(figi)\n",
    "            async for event in streaming:\n",
    "                #print(event)\n",
    "                if str(event.event)=='Event.candle':\n",
    "                    cur_events[0] = event\n",
    "                elif str(event.event)=='Event.orderbook':\n",
    "                    cur_events[1] = event\n",
    "                elif str(event.event)=='Event.instrument_info':\n",
    "                    cur_events[2] = event\n",
    "                if (time.time() - start_time) >= (collect_duration+countdown+5):\n",
    "                    await streaming.stop()\n",
    "        except asyncio.TimeoutError:\n",
    "            print('Stream stopped!')\n",
    "\n",
    "# Collecting coroutine. Makes collecting data from current events provided by concurrent streaming\n",
    "async def collect(duration,depth,sample_time,period,countdown=60-time.gmtime().tm_sec-time.time()%1):\n",
    "    if sample_time%period==0:\n",
    "        global X,gmtimes\n",
    "        X,gmtimes=[],[]\n",
    "        await asyncio.sleep(countdown)\n",
    "        start_time = time.time()\n",
    "        current = 0\n",
    "        sample_num = 0\n",
    "        parts_number = int(round(sample_time/period))\n",
    "        sample = np.zeros(((2*depth+1)*parts_number))\n",
    "        part_vars = []\n",
    "        for i in range(parts_number):\n",
    "            locals()['part' + str(i)] = i\n",
    "            part_vars.append(locals()['part' + str(i)])\n",
    "        while time.time() <= start_time + duration:\n",
    "            if (cur_events[2].payload.trade_status=='normal_trading'):\n",
    "                if current!=0:\n",
    "                    last = round(current)\n",
    "                else:\n",
    "                    last = time.time() - period\n",
    "                gmtime = time.gmtime()\n",
    "                current = time.time()\n",
    "                if round(gmtime.tm_sec+current%1)==60:\n",
    "                    part_num=0\n",
    "                else:\n",
    "                    part_num = int(round(gmtime.tm_sec+current%1)//period)\n",
    "                #print('{}:{}:{:.2f}'.format(gmtime.tm_hour,gmtime.tm_min,gmtime.tm_sec+time.time()%1))\n",
    "                # sample[parts_number+(2*depth)*part_num:parts_number+(2*depth)*part_num+depth] = np.array(cur_events[1].payload.bids)[:,1]\n",
    "                # sample[parts_number+(2*depth)*part_num+depth:parts_number+(2*depth)*part_num+2*depth] = np.array(cur_events[1].payload.asks)[:,1]\n",
    "                # sample[part_num] = cur_events[0].payload.c\n",
    "                part_vars[part_num] = np.hstack([np.array(cur_events[0].payload.c),np.array(cur_events[1].payload.bids)[:,1],np.array(cur_events[1].payload.asks)[:,1]])\n",
    "                if (part_num==int((parts_number-1))):\n",
    "                    sample = np.hstack(part_vars)\n",
    "                    if len(sample)==(2*depth+1)*parts_number:\n",
    "                        gmtimes.append(gmtime)\n",
    "                        X.append(sample)\n",
    "                        print('Sample #{} added'.format(sample_num))\n",
    "                        sample_num+=1\n",
    "            else:\n",
    "                print('Not a good time for trading')\n",
    "            await asyncio.sleep(period-(current-last-period))\n",
    "        print('Collection complete!')\n",
    "    else:\n",
    "        print('Sample time must be a multiple of the period')\n",
    "\n",
    "# Coroutine that runs concurrent coroutines\n",
    "async def gather_tasks(token,figi,collect_duration,candle_resolution,depth,sample_time,period):\n",
    "    tasks = [asyncio.create_task(stream(token,figi,collect_duration,candle_resolution,depth)),\n",
    "             asyncio.create_task(collect(collect_duration,depth,sample_time,period))\n",
    "            ]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Run event loop with concurrent tasks\n",
    "#loop = asyncio.get_event_loop()\n",
    "#loop.run_until_complete(gather_tasks(TOKEN_SANDBOX,FIGI,duration,candle_resolution,depth,sample_time,period))\n",
    "#loop.close()\n",
    "await gather_tasks(TOKEN_SANDBOX,FIGI,duration,candle_resolution,depth,sample_time,period)\n",
    "\n",
    "# Make csv with collected data\n",
    "np_X = np.array(X)\n",
    "df_X = pd.DataFrame(data=np_X,index=gmtimes)\n",
    "#print(df_X)\n",
    "df_X.to_csv('df_X_MRNA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X = np.array(X)\n",
    "gmtimes = [pd.to_datetime('10:33:00 04-05-2021')+i*dt.timedelta(minutes=1) for i in range(662)]\n",
    "df_X = pd.DataFrame(data=np_X,index=gmtimes[:len(X)])\n",
    "df_X.to_csv('df_X_SPCE.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
